---
title: "Assignment 1"
author: "Group 75"
date: "2/15/2022"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, results='hide'}
library(tidyverse)
library(ggpubr)
library(rstatix)
install.packages("lme4")
```

##Exercise 1: Waiting Time at a Doctor's office (a) Below, the measured waiting time in the waiting room of doctor's office is given of 15 people. This waiting time is represented in a vector of length 15, where the mean waiting time is a little more than 11 minutes.

```{r waiting_t}
waiting_t <- c(15.4, 17.9, 19.0, 0.5, 15.9, 2.7, 6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7)
mu_t = mean(waiting_t)
format(round(mu_t, 3), nsmall = 3) #rounding off to 3 decimals places 
```

There are several ways to check normality of the waiting time data, such as a histogram, QQ-plot, Shapiro-wilk Test.The Histogram and QQ-plot are graphical ways to check normality, and the Shapiro-wilk test is a statistical test to check normality. In the Shapiro-wilk test, the null-hypothesis claims that the sample data comes from a normal distribution, and the alternative hypothesis claims that the sample data does not come from normal distribution. This means that when the p-value is above the confidence level of \alpha=0.05, that the sample data does come from normal distribution since the null hypothesis cannot be rejected.

Below, we will perform all of these normality checks.

```{r, echo=FALSE}
par(mfrow=c(1,2))
hist(waiting_t, main='Histogram of Waiting time')
qqnorm(waiting_t, main='QQ-Plot of Waiting Time')
qqline(waiting_t)
```

According to the histogram, it seems that the waiting time data does not come from a normal distribution. However, the sample size is very small, which could influence this graphical test. The QQ-plot shows a quite straight line of the sample data and therefore this could mean that the sample data comes from normal distribution. To make the normality check final, the Shapiro-Wilk test is performed to accept this assumption that the sample data comes from normal distribution.

```{r, echo=FALSE, results='hide'}
options(digits=5)
shapiro.test(waiting_t)
```

The result of the Shapiro-wilk test shows a p-value of 0.3. This means that the data of the waiting time is normally distributed. To construct a 97%-CI, the following formula needs to be computed: mean(sample) +- z\*se where se is the standard error which is computed by: sd/sqrt(n) where n is the sample size

```{r, echo=FALSE, results='hide'}
#97% CI means an alpha of 0.03
z <- qnorm(0.985) #get z(alpha/2)
me_t <- z*((sd(waiting_t))/sqrt(15))
Lb <- round((mu_t - me_t), 3)
Ub <- round((mu_t + me_t), 3)
sprintf("%f is Lower Bound", Lb)
sprintf("%f is Upper Bound",Ub)
```

The upper and lower bound of 97%-CI is [6.743, 15.403]

```{r, echo=FALSE, results='hide'}
#97% CI means an alpha of 0.03
z <- qnorm(0.985) #get z(alpha/2)
sd_t <- (sd(waiting_t))
E = 2
sample_size <- round((z^2 * sd_t^2/E^2), 3)
sprintf("%f is minimum sample size",sample_size)
```

Bootstrap

```{r, results='hide'}
B=1000
Tstar = numeric(B)
for(i in 1:B){
  Xstar=sample(waiting_t, replace=TRUE)
  Tstar[i]=mean(Xstar)}
Tstar15=quantile(Tstar, 0.015)
Tstar985=quantile(Tstar, 0.985)
sum(Tstar<Tstar15)
round(c(2*mu_t-Tstar985, 2*mu_t-Tstar15), 3)
```

The 97% bootstrap CI is [6.61, 14.86] The original CI was [6.743, 15.403], which means that the bootstrap 97%-CI and the original 97%-CI do not differ much.

(b) Claim: mean waiting time \< 15 H0: mean waiting time \>= 15 H1: mean waiting time \< 15 Since the data comes from a normal distribution (see normality check at top of document), a t-test can be used. We only have one data sample, and therefor perform a one sample t-test.

```{r, echo=FALSE, results='hide'}
t.test(waiting_t, mu =15, alternative="less")
```

The p-value for this one-sample t-test is 0.03, which means that the null-hypothesis can be rejected and that the mean of the data sample indeed is less than 15. The CI-interval for this t-test is [-âˆž, 14.6], which means that we can be 95% sure that the mean of the data sample lies within the CI-interval.

In the sign test we care about the median instead of the mean. Our hypotheses H0 and H1 are still the same as in the one-sample t-test, but instead of mean we use median. The hypothesized median is 15.

```{r, echo=FALSE, results='hide'}
above_m <- sum(waiting_t<15)
binom.test(above_m, length(waiting_t), p=0.5, alternative = "less")
```

For this problem, the Wilcoxon signed rank test could also be performed. This test needs a sample from a symmetric population and cares about the median.

(c) Compute powers of t-test and sign test

```{r, echo=FALSE, results='hide'}
sd = sd(waiting_t)
B=1000; n= 50
psign= numeric(B)
pttest = numeric(B)
for(i in 1:B) {
  x=rnorm(n,mean=13, sd = sd) ## generate data under H1 with mu=13
  pttest[i]=t.test(x, mu =15, alternative="less")[[3]] ## extract p-value
  above_m <- sum(x<15)
  psign[i]=binom.test(above_m, n, p=0.5, alternative = "less")[[3]]}
sum(psign<0.05)/B
sum(pttest<0.05)/B
B=1000; n= 50
psign2= numeric(B)
pttest2 = numeric(B)
for(i in 1:B) {
  x=rnorm(n,mean=14,sd= sd) ## generate data under H1 with mu=14
  above_m <- sum(x<15)
  pttest2[i]=t.test(x, mu =15, alternative="less")[[3]] ## extract p-value
  psign2[i]=binom.test(above_m, n, p=0.5, alternative = "less")[[3]]
  
  }
sum(psign2<0.05)/B
sum(pttest2<0.05)/B
```

By comparing the power of the t-test and the sign-test, we can see that the power of the t-test is higher than the power of the sign test. Therefore, the t-test is a better test for this application. A reason for this is that a t-test depends on normality and the data comes from a normal distribution. So, therefore the t-test is more reliable.

(d) 

```{r, echo=FALSE, results='hide'}
n = length(waiting_t) #sample size
p_hat_r = 0.53 #right end of CI
point_est = (sum(waiting_t>15.5))/n #probability that people have to wait longer than 15.5 minutes
SE= sqrt(point_est*(1-point_est)/n) #Calculating standard error of proportions

#point estimate + m = 0.53
#m = 0.53 - point estimate
m = p_hat_r - point_est
p_hat_l = point_est - m 
CI_p = c(p_hat_l, p_hat_r)
print(CI_p)
#calculate confidence level
#m = z * SE
#confidence level can be calculated using z
#z = m/SE
z = m/SE
CL = pnorm(z)-(1-pnorm(z)) #calculating 2 sided confidence level
CL
```
The recovered confidence interval of the probability that a patient has to wait longer than 15.5 minutes is [0.137, 0.53], and this has a confidence level of 89.39%


(e) Test of proportions H0: Proportion of long waiters of man is equal to proportion of long waiters of woman Ha: Proportions are different

```{r, echo=FALSE, results='hide'}
prop.test(x=c(3, 2), n = c(7, 8))
```

The p-value is 0.853, which is much larger than 0.05. Therefore, the waiting time for man and woman are the same.

##Exercise 4: Hemoglobin in trout

```{r, echo=FALSE, results='hide'}
data_h = read.table(file="hemoglobin.txt",header=TRUE)
data_h$rate = as.factor(data_h$rate)
data_h$method = as.factor(data_h$method)
data_h$hemoglobin = as.numeric(as.character(data_h$hemoglobin))
df = data.frame(data_h)
df
```

(a) 

```{r, echo=FALSE, results='hide'}
I=4 #4 levels of rate
J=2 #2 levels of method
N=10 #80 observations/fishes
rbind(rep(1:I,each=N*J),rep(1:J,N*I),sample(1:(N*I*J)))
```

(b) Check for normality before using ANOVA-test. The data comes from normal distributions, since both the histogram and QQ-plot show a normally distributed graph. Besides, the shapiro-wilk test gives a p-value of 0.526 which is above 0.05 and therefore suggests that the data comes from normal distribution.

```{r, echo=FALSE, results='hide'}
model_h = lm(hemoglobin ~ rate*method, data=df)
#Visualizations on normality
par(mfrow=c(1,2))
hist(residuals(model_h), main='Histogram of residuals of model') 
qqnorm(residuals(model_h), main='QQ-Plot of residuals of model')
qqline(residuals(model_h))
#test on normality 
shapiro.test(residuals(model_h)) 
```

```{r, echo=FALSE, results='hide'}
#Performing Anova Test
anova(model_h)
summary(model_h)
```

From the two-way ANOVA test, we can see that the treatment variable 'rate' has a significant effect on hemoglobin, since the p-value is below 0.05. However, the block variable 'method' does not have a significant effect on hemoglobin since it's p-value is 0.216, which is above 0.05. The p-value for rate:method is 0.377, which means that there is no evidence for interaction.

(c) The factor 'rate' has the greatest influence on hemoglobin, since rate has a significant effect on hemoglobin and method does not have a significant effect on hemoglobin. However, since there is no interaction between rate and method, we have to remove the interaction term from the model and create an additive model where there is no interaction. Still, only the variable rate has a main effect on hemoglobin, and not the variable 'method'.

```{r, echo=FALSE, results='hide'}
model_new = lm(hemoglobin ~ rate+method, data=df)
anova(model_new)
summary(model_new)
df
```

```{r, echo=FALSE, results='hide'}
methA = df[which(df$method == 'A'),]
methB = df[which(df$method == 'B'),]
rate_mA <- with(methA, tapply(hemoglobin, rate, mean))
rate_mB <- with(methB, tapply(hemoglobin, rate, mean))
rate_mA; rate_mB
```

The combination of rate 2 and method B leads to the highest mean of hemoglobin

Estimate the mean hemoglobin value for rate 3 by using method A.

```{r, echo=FALSE, results='hide'}
meth_a3 = df[which(df$method == 'A' & df$rate == 3),] #filter dataframe where rate=3 and method=A
hemo = meth_a3[,1] #select hemoglobin column
mean(hemo)
```

The mean of rate 3 and method A is 9.03

```{r, echo=FALSE, results='hide'}
rate_m <- with(df, tapply(hemoglobin, rate, mean))
rate_m
```

Rate 2 leads to the highest mean of hemoglobin

(d) 

```{r, echo=FALSE, results='hide'}
model_1 = lm(hemoglobin ~ rate, data=df)
anova(model_1)
summary(model_1)
```

The results from the one-way ANOVA are exactly equal to the results of the two-way ANOVA. In both tests the effect of each rate on hemoglobin is tested and therefore, it is unnecessary to do the one-way ANOVA.

##Exercise 5: Sour Cream (a) To perform a three-way ANOVA test, we need to check normality. This is done by creating a QQ-plot and histogram of the residuals of the data. Additionally, the Shapiro-Wilk test was performed. The line in the QQ-plot looks linear and the distribution of the histogram can come from a normal distribution. Besides, the Shapiro-Wilk test had a p-value larger than 0.05 which means that the data comes from normal distribution. Therefore, a three-way ANOVA can be performed.

```{r, echo=FALSE, results='hide'}
data = read.table(file="cream.txt",header=TRUE)
data$batch = as.factor(data$batch)
data$position = as.factor(data$position)
data$starter = as.factor(data$starter)
data$acidity = as.numeric(as.character(data$acidity))
df = data.frame(data)
model  <- lm(acidity ~ batch+position+starter, data = df)
#Visualizations on normality
par(mfrow=c(1,2))
hist(residuals(model), main='Histogram of residuals of model') 
qqnorm(residuals(model), main='QQ-Plot of residuals of model')
qqline(residuals(model))
#test on normality 
shapiro.test(residuals(model)) 
#Performing Anova Test
anova(model)
summary(model)
```

Starter 1 is the intercept, which has a p-value of less than 0.05. Therefore there is a significant effect of starter 1 on acidity. While starter 2 has a p-value of 0.754, and therefore has no significant effect on acidity.

(b) Insignificant block variables, are variables that have a p-value larger than 0.05. So this is the block variable position, which has a p-value of 0.411

```{r, echo=FALSE, results='hide'}
model  <- lm(acidity ~ batch+starter, data = df)
#Performing Anova Test
anova(model)
summary(model)
```

After deleting the block variable position, starter 4 leads to a significantly different acidity.

(c) In the Friedman test the data does not need to come from a normal distribution, but it can also be used when the data comes from a normal distribution, like in this case. Instead of using the mean of the groups in an ANOVA test the Friedman makes use of ranks. However, this difference does not make any difference in the use of this test. Therefore, the Friedman test can also be used in this application to test whether there is an effect of starter on acidity. However, the Friedman test is not necessary when the ANOVA test has already been perfromed.

(d) Formula mixed effects is acidity \~ starter+(1\|batch). Where the 1\|batch is used to make from the block variable 'batch' a random effect variable.

```{r, echo=FALSE, results='hide'}
model_new  = lmer(acidity ~ starter+(1|batch) , data = df, REML=FALSE)
model  <- lm(acidity ~ batch+starter, data = df)
#Performing Anova Test
anova(model_new)
summary(model_new)
```

When using the fixed effects model the variables 1 and starter 4 had a significant effect on acidity. In the mixed effects model variables starter 1, starter 3, starter 4 had a significant effect on acidity. So, with the mixed effect model, more starters have a significant effect on acidity.