---
title: "Assignment 1"
author: "Group 75"
date: "2/15/2022"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE, results='hide'}
library(tidyverse)
library(ggpubr)
library(rstatix)
install.packages("lme4")
```

##Exercise 1: Waiting Time at a Doctor's office
(a) Below, the measured waiting time in the waiting room of doctor's office is given of 15 people. This waiting time is represented in a vector of length 15, where the mean waiting time is a little more than 11 minutes.


```{r waiting_t}
waiting_t <- c(15.4, 17.9, 19.0, 0.5, 15.9, 2.7, 6.2, 2.5, 4.7, 6.9, 10.8, 24.3, 5.6, 23.0, 10.7)
mu_t = mean(waiting_t)
format(round(mu_t, 3), nsmall = 3) #rounding off to 3 decimals places 
```
There are several ways to check normality of the waiting time data, such as a histogram, QQ-plot, Shapiro-wilk Test.The Histogram and QQ-plot are graphical ways to check normality, and the Shapiro-wilk test is a statistical test to check normality. In the Shapiro-wilk test, the null-hypothesis claims that the sample data comes from a normal distribution, and the alternative hypothesis claims that the sample data does not come from normal distribution. This means that when the p-value is above the confidence level of \alpha=0.05, that the sample data does come from normal distribution since the null hypothesis cannot be rejected. 

Below, we will perform all of these normality checks.

```{r, echo=FALSE}
par(mfrow=c(1,2))
hist(waiting_t, main='Histogram of Waiting time')
qqnorm(waiting_t, main='QQ-Plot of Waiting Time')
qqline(waiting_t)
```
According to the histogram, it seems that the waiting time data does not come from a normal distribution. However, the sample size is very small, which could influence this graphical test. The QQ-plot shows a quite straight line of the sample data and therefore this could mean that the sample data comes from normal distribution.
To make the normality check final, the Shapiro-Wilk test is performed to accept this assumption that the sample data comes from normal distribution.

```{r, echo=FALSE, results='hide'}
shapiro.test(waiting_t)
```
The result of the Shapiro-wilk test shows a p-value of 0.3. This means that the data of the waiting time is normally distributed. 
To construct a 97%-CI, the following formula needs to be computed: mean(sample) +- z*se
where se is the standard error which is computed by: sd/sqrt(n)
where n is the sample size

```{r, echo=FALSE, results='hide'}
#97% CI means an alpha of 0.03
z <- qnorm(0.985) #get z(alpha/2)
me_t <- z*((sd(waiting_t))/sqrt(15))
Lb <- mu_t - me_t
Ub <- mu_t + me_t
sprintf("%f is Lower Bound", Lb)
sprintf("%f is Upper Bound",Ub)
```
The upper and lower bound of 97%-CI is [6.743, 15.403]


```{r, echo=FALSE, results='hide'}
#97% CI means an alpha of 0.03
z <- qnorm(0.985) #get z(alpha/2)
sd_t <- (sd(waiting_t))
E = 2
sample_size <- z^2 * sd_t^2/E^2
sprintf("%f is minimum sample size", sample_size)
```
Bootstrap
```{r, results='hide'}
B=1000
Tstar = numeric(B)
for(i in 1:B){
  Xstar=sample(waiting_t, replace=TRUE)
  Tstar[i]=mean(Xstar)}
Tstar15=quantile(Tstar, 0.015)
Tstar985=quantile(Tstar, 0.985)
sum(Tstar<Tstar15)

c(2*mu_t-Tstar985, 2*mu_t-Tstar15)
```
The 97% bootstrap CI is [6.61, 14.86]
The original CI was [6.743, 15.403], which means that the bootstrap 97%-CI and the original 97%-CI do not differ much.

(b)
Claim: mean waiting time < 15
H0: mean waiting time >= 15
H1: mean waiting time < 15
Since the data comes from a normal distribution (see normality check at top of document), a t-test can be used. 
We only have one data sample, and therefor perform a one sample t-test.
```{r, echo=FALSE, results='hide'}
t.test(waiting_t, mu =15, alternative="less")
```
The p-value for this one-sample t-test is 0.03, which means that the null-hypothesis can be rejected and that the mean of the data sample indeed is less than 15. 
The CI-interval for this t-test is [-âˆž, 14.6], which means that we can be 95% sure that the mean of the data sample lies within the CI-interval.

In the sign test we care about the median instead of the mean.
Our hypotheses H0 and H1 are still the same as in the one-sample t-test, but instead of mean we use median.
The hypothesized median is 15.

```{r, echo=FALSE, results='hide'}
above_m <- sum(waiting_t<15)
binom.test(above_m, length(waiting_t), p=0.5, alternative = "less")
```
For this problem, the Wilcoxon signed rank test could also be performed. This test needs a sample from a symmetric population and cares about the median. 

(c)
Compute powers of t-test and sign test

```{r, echo=FALSE, results='hide'}
power.t.test(length(waiting_t), delta = 1, alternative = "one.sided") #mu_new = 14
power.t.test(length(waiting_t), delta = 2, alternative = "one.sided") #mu_new = 13
#pbinom(length(waiting_t), alternative= "one.sided") # cares about median so the power does not dependent on a different mu?
```
(d)

```{r, echo=FALSE, results='hide'}
p_hat_r = 0.53 #right end of CI
n = 15 #sample size
SE= sqrt((p_hat_r*(1-p_hat_r))/n) #Calculating sample error
p_hat_l = p_hat_r - (4*SE) #95% confidence interval, difference of 4 sigmas between left and right bound of CI 
CI_p = c(p_hat_l, p_hat_r)
print(CI_p)
```


(e)
Test of proportions
H0: Proportion of long waiters of man is equal to proportion of long waiters of woman
Ha: Proportions are different 
```{r, echo=FALSE, results='hide'}
prop.test(x=c(3, 2), n = c(7, 8))
```
The p-value is 0.853, which is much larger than 0.05. Therefore, the waiting time for man and woman are the same.

##Exercise 5: Sour Cream
(a) 
To perform a three-way ANOVA test, we need to check normality. This is done by creating a QQ-plot and histogram of the residuals of the data. Additionally, the Shapiro-Wilk test was performed. The line in the QQ-plot looks linear and the distribution of the histogram can come from a normal distribution. Besides, the Shapiro-Wilk test had a p-value larger than 0.05 which means that the data comes from normal distribution. Therefore, a three-way ANOVA can be performed. 
```{r, echo=FALSE, results='hide'}
data = read.table(file="cream.txt",header=TRUE)
data$batch = as.factor(data$batch)
data$position = as.factor(data$position)
data$starter = as.factor(data$starter)
data$acidity = as.numeric(as.character(data$acidity))

df = data.frame(data)

model  <- lm(acidity ~ batch+position+starter, data = df)

#Visualizations on normality
par(mfrow=c(1,2))
hist(residuals(model), main='Histogram of residuals of model') 
qqnorm(residuals(model), main='QQ-Plot of residuals of model')
qqline(residuals(model))
#test on normality 
shapiro.test(residuals(model)) 

#Performing Anova Test
anova(model)
summary(model)
```
Starter 1 is the intercept, which has a p-value of less than 0.05. Therefore there is a significant effect of starter 1 on acidity. While starter 2 has a p-value of 0.754, and therefore has no significant effect on acidity. 

(b)
Insignificant block variables, are variables that have a p-value larger than 0.05. So this is the block variable position, which has a p-value of 0.411
```{r, echo=FALSE, results='hide'}
model  <- lm(acidity ~ batch+starter, data = df)

#Performing Anova Test
anova(model)
summary(model)
```
After deleting the block variable position, starter 4 leads to a significantly different acidity. 

(c)
In the Friedman test the data does not need to come from a normal distribution, but it can also be used when the data comes from a normal distribution, like in this case. Instead of using the mean of the groups in an ANOVA test the Friedman makes use of ranks. However, this difference does not make any difference in the use of this test. Therefore, the Friedman test can also be used in this application to test whether there is an effect of starter on acidity. 

(d)
How to determine the formula for the mixed effect?

```{r, echo=FALSE, results='hide'}
model_new  = lmer(acidity ~ starter+batch+(1|position) , data = df, REML=FALSE)
model1 = lmer(acidity ~ batch+(1|position) , data = df, REML=FALSE)
#Performing Anova Test
anova(model_new)
summary(model_new)
anova(model1, model_new)
```
When using the fixed effects model the variables ... had a significant effect on acidity. In the mixed effects model variables ... had a significant effect on acidity. 


